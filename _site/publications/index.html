<!-- This layout is used in all pages. Making changes here will effect all pages. We recommend not to change anything here. --> <!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="dns-prefetch" href="//fonts.googleapis.com"><link rel="dns-prefetch" href="//google-analytics.com"><link rel="dns-prefetch" href="//www.google-analytics.com"><link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com"><link rel="dns-prefetch" href="//code.jquery.com"><link rel="dns-prefetch" href="//fonts.gstatic.com"><title>Publications | Zhaocheng Zhu</title><meta name="generator" content="Jekyll v3.8.4" /><meta property="og:title" content="Publications" /><meta property="og:locale" content="en_US" /><meta name="description" content="Zhaocheng Zhu’s homepage" /><meta property="og:description" content="Zhaocheng Zhu’s homepage" /><link rel="canonical" href="kiddozhu.github.io/publications/" /><meta property="og:url" content="kiddozhu.github.io/publications/" /><meta property="og:site_name" content="Zhaocheng Zhu" /><link rel="next" href="kiddozhu.github.io/publications/2/" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Publications" /><script type="application/ld+json"> {"@type":"WebPage","headline":"Publications","url":"kiddozhu.github.io/publications/","description":"Zhaocheng Zhu’s homepage","@context":"https://schema.org"}</script><meta property="og:image" content="kiddozhu.github.io" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"><link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png"><link rel="manifest" href="/assets/icons/site.webmanifest"><link rel="mask-icon" href="/assets/icons/safari-pinned-tab.svg" color="#6e006e"><link rel="shortcut icon" href="/assets/icons/favicon.ico"><meta name="msapplication-TileColor" content="#6e006e"><meta name="msapplication-config" content="/assets/icons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.7.3/Chart.bundle.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css"><link rel='stylesheet prefetch' href="https://cdn.rawgit.com/yairEO/photobox/master/photobox/photobox.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script><script src="https://cdn.rawgit.com/yairEO/photobox/master/photobox/jquery.photobox.js"></script></head><body><div class="loader"><div class="lds-ring"><div></div><div></div><div></div><div></div></div></div><div class="wrapper"><div class="container-grid"><div class="sidebar"><div class="author-container shadow"><div class="author"><img src="/assets/images/avatar.jpg" width="100%" height="auto;" alt="Zhaocheng Zhu" onclick="location.href='/'"></div><div class="about text-center"><h1 class="title"><a href="/">Zhaocheng Zhu</a></h1></div><div class="bio text-center"> <p class="m0">Researcher</p></div><hr class="dashed"><div class="social text-center"> <ul class="portfolio p0"> <li><a class="active" href="/publications/">Publications</a></li> <li><a href="/projects/">Projects</a></li> <li><a href="/random/">Random</a></li> </ul> <ul class="sm p0 m0a"> <li><a href="https://scholar.google.com/citations?user=Qd8JumkAAAAJ" title="Google Scholar"><i class="ai ai-google-scholar"></i></a></li> <li><a href="https://github.com/KiddoZhu" title="GitHub"><i class="fa fa-github"></i></a></li> <li><a href="https://www.linkedin.com/in/zhaocheng-zhu-24756213b/" title="LinkedIn"><i class="fa fa-linkedin"></i></a></li> <li><a href="https://x.com/zhu_zhaocheng" title="Twitter"><i class="fa fa-twitter"></i></a></li> </ul></div><div style="width:100px; margin:15px auto"><script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=y8pu6e0XidZPRVfp4dm8eSw7Lc7f-EQQFdHjHRzVsKI"></script></div></div></div><div class="main"><div class="main-container shadow"><div class="title-space"> <h1>Publications</h1><div class="input-group mb-3" data-aos="zoom-in"> <input type="text" class="form-control" id="search-input"><div class="input-group-append"> <span class="input-group-text"><i class="fa fa-search"></i></span></div></div></div><hr class="dashed"> <main> <main> <ul class="breadcrumbs"> <li><a href="/">Home</a></li> <li><a href="#">Publications</a></li> </ul> <article><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/biomedical-knowledge-graph-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Path-based Reasoning for Biomedical Knowledge Graphs with BioKGC</h5> Yue Hu, Svitlana Oleshko, Samuele Firmani, <b>Zhaocheng Zhu</b>, Hui Cheng, Maria Ulmer, Matthias Arnold, Maria Colomé-Tatché, Jian Tang, Sophie Xhonneux, Annalisa Marsico <br /> bioRxiv 2024 &nbsp; <a href="https://www.biorxiv.org/content/10.1101/2024.06.17.599219v1.full.pdf">Paper</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/molecule-multi-task-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Towards Foundation Models for Molecular Learning on Large-Scale Multi-Task Datasets</h5> Dominique Beaini, et al. (34 authors) <br /> ICLR 2024 &nbsp; <a href="https://arxiv.org/pdf/2310.04292.pdf">Paper</a> / <a href="https://github.com/datamol-io/graphium">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/reasoning-foundation-model-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Towards Foundation Models for Knowledge Graph Reasoning</h5> Mikhail Galkin, Xinyu Yuan, Hesham Mostafa, Jian Tang, <b>Zhaocheng Zhu</b> <br /> ICLR 2024 &nbsp; <a href="https://arxiv.org/pdf/2310.04562.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/ULTRA">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/graphany-thumbnail.jpg);"></div><div class="content"> <h5 class="title">GraphAny: A Foundation Model for Node Classification on Any Graph</h5> Jianan Zhao, Hesham Mostafa, Mikhail Galkin, Michael Bronstein, <b>Zhaocheng Zhu</b>, Jian Tang <br /> arXiv 2024 &nbsp; <a href="https://arxiv.org/pdf/2405.20445">Paper</a> / <a href="https://github.com/DeepGraphLearning/GraphAny">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/zero-shot-logical-query-thumbnail.jpg);"></div><div class="content"> <h5 class="title">A Foundation Model for Zero-shot Logical Query Reasoning</h5> Mikhail Galkin, Jincheng Zhou, Bruno Ribeiro, Jian Tang, <b>Zhaocheng Zhu</b> <br /> NeurIPS 2024 &nbsp; <a href="https://arxiv.org/pdf/2404.07198.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/ULTRA">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/a-star-net-thumbnail.jpg);"></div><div class="content"> <h5 class="title">A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs</h5> <b>Zhaocheng Zhu</b>*, Xinyu Yuan*, Mikhail Galkin, Sophie Xhonneux, Ming Zhang, Maxime Gazeau, Jian Tang <br /> NeurIPS 2023 &nbsp; <a href="https://arxiv.org/pdf/2206.04798.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/AStarNet">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/graphtext-thumbnail.jpg);"></div><div class="content"> <h5 class="title">GraphText: Graph Reasoning in Text Space</h5> Jianan Zhao, Le Zhuo, Yikang Shen, Meng Qu, Kai Liu, Michael Bronstein, <b>Zhaocheng Zhu</b>, Jian Tang <br /> arXiv 2023 &nbsp; <a href="https://arxiv.org/pdf/2310.01089.pdf">Paper</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/llm-rule-learning-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Large Language Models can Learn Rules</h5> <b>Zhaocheng Zhu</b>, Yuan Xue, Xinyun Chen, Denny Zhou, Jian Tang, Dale Schuurmans, Hanjun Dai <br /> arXiv 2023 &nbsp; <a href="https://arxiv.org/pdf/2310.07064.pdf">Paper</a> / <a href="https://github.com/google-deepmind/llms_can_learn_rules/">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/neural-graph-database-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Neural Graph Reasoning: Complex Logical Query Answering Meets Graph Databases</h5> Hongyu Ren*, Mikhail Galkin*, Michael Cochez, <b>Zhaocheng Zhu</b>, Jure Leskovec <br /> arXiv 2023 &nbsp; <a href="https://arxiv.org/pdf/2303.14617.pdf">Paper</a> / <a href="https://github.com/neuralgraphdatabases/awesome-logical-query">Paper List</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/protein-sequence-benchmark-thumbnail.jpg);"></div><div class="content"> <h5 class="title">PEER: A Comprehensive and Multi-Task Benchmark for Protein Sequence Understanding</h5> Minghao Xu*, Zuobai Zhang*, Jiarui Lu, <b>Zhaocheng Zhu</b>, Yangtian Zhang, Chang Ma, Runcheng Liu, Jian Tang <br /> NeurIPS (Datasets and Benchmarks Track) 2022 &nbsp; <a href="https://arxiv.org/pdf/2206.02096.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/PEER_Benchmark">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/inductive-logical-query-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Inductive Logical Query Answering in Knowledge Graphs</h5> Mikhail Galkin, <b>Zhaocheng Zhu</b>, Hongyu Ren, Jian Tang <br /> NeurIPS 2022 &nbsp; <a href="https://arxiv.org/pdf/2210.08008.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/InductiveQE">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/gnn-qe-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Neural-Symbolic Models for Logical Queries on Knowledge Graphs</h5> <b>Zhaocheng Zhu</b>, Mikhail Galkin, Zuobai Zhang, Jian Tang <br /> ICML 2022 &nbsp; <a href="https://arxiv.org/pdf/2205.10128.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/GNN-QE">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/torchdrug-thumbnail.jpg);"></div><div class="content"> <h5 class="title">TorchDrug: A Powerful and Flexible Machine Learning Platform for Drug Discovery</h5> <b>Zhaocheng Zhu</b>, Chence Shi, Zuobai Zhang, Shengchao Liu, Minghao Xu, Xinyu Yuan, Yangtian Zhang, Junkun Cheng, Huiyu Cai, Jiarui Lu, Chang Ma, Runcheng Liu, Louis-Pascal Xhonneux, Meng Qu, Jian Tang <br /> arXiv 2022 <span class="emphasis">(65k+ downloads)</span> &nbsp; <a href="https://arxiv.org/pdf/2202.08320.pdf">Paper</a> / <a href="https://torchdrug.ai/">Website</a> / <a href="https://colab.research.google.com/drive/1Tbnr1Fog_YjkqU1MOhcVLuxqZ4DC-c8-#forceEdit=true&amp;sandboxMode=true">Tutorial</a> / <a href="https://github.com/DeepGraphLearning/torchdrug">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/neural-bellman-ford-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction</h5> <b>Zhaocheng Zhu</b>, Zuobai Zhang, Louis-Pascal Xhonneux, Jian Tang <br /> NeurIPS 2021 <br /> <a href="https://papers.nips.cc/paper/2021/file/f6a673f09493afcd8b129a0bcf1cd5bc-Paper.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/NBFNet">Code (original)</a> / <a href="https://github.com/DeepGraphLearning/AStarNet">Code (new)</a> / <a href="https://github.com/KiddoZhu/NBFNet-PyG">Code (PyG)</a> / <a href="https://ogb.stanford.edu/kddcup2021/results/#final_wikikg90m">OGB-LSC</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/kepler-thumbnail.jpg);"></div><div class="content"> <h5 class="title">KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation</h5> Xiaozhi Wang, Tianyu Gao, <b>Zhaocheng Zhu</b>, Zhiyuan Liu, Juanzi Li, Jian Tang <br /> TACL 2021 &nbsp; <a href="https://arxiv.org/pdf/1911.06136.pdf">Paper</a> / <a href="https://github.com/THU-KEG/KEPLER">Code</a> / <a href="https://deepgraphlearning.github.io/project/wikidata5m">Dataset</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/graphaf-thumbnail.jpg);"></div><div class="content"> <h5 class="title">GraphAF: A Flow-based Autoregressive Model for Molecular Graph Generation</h5> Chence Shi*, Minkai Xu*, <b>Zhaocheng Zhu</b>, Weinan Zhang, Ming Zhang, Jian Tang <br /> ICLR 2020 &nbsp; <a href="https://arxiv.org/pdf/2001.09382.pdf">Paper</a> / <a href="https://github.com/DeepGraphLearning/GraphAF">Code</a> / <a href="https://colab.research.google.com/drive/1JEMiMvSBuqCuzzREYpviNZZRVOYsgivA?usp=sharing">Tutorial (TorchDrug)</a> / <a href="https://github.com/DeepGraphLearning/torchdrug/blob/master/torchdrug/tasks/generation.py">Code (TorchDrug)</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/network-pruning-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Self-Adaptive Network Pruning</h5> Jinting Chen, <b>Zhaocheng Zhu</b>, Cheng Li, Yuming Zhao <br /> ICONIP 2019 <span class="emphasis">(Best Student Paper Finalist)</span> &nbsp; <a href="https://arxiv.org/pdf/1910.08906.pdf">Paper</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/graphvite-thumbnail.jpg);"></div><div class="content"> <h5 class="title">GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding</h5> <b>Zhaocheng Zhu</b>, Shizhen Xu, Meng Qu, Jian Tang <br /> WWW 2019 <span class="emphasis">(68k+ downloads)</span> &nbsp; <a href="https://arxiv.org/pdf/1903.00757.pdf">Paper</a> / <a href="https://graphvite.io/">Website</a> / <a href="https://graphvite.io/tutorials">Tutorial</a> / <a href="https://github.com/DeepGraphLearning/graphvite">Code</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/saliency-supervision-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Saliency Supervision: An Intuitive and Effective Approach for Pain Intensity Regression</h5> Conghui Li, <b>Zhaocheng Zhu</b>, Yuming Zhao <br /> ICONIP 2018 &nbsp; <a href="https://arxiv.org/pdf/1811.07987.pdf">Paper</a></div></div><div class="blog cards borders blog-list"><div class="image" style="background-image: url(/assets/images/papers/document-embedding-thumbnail.jpg);"></div><div class="content"> <h5 class="title">Context Aware Document Embedding</h5> <b>Zhaocheng Zhu</b>, Junfeng Hu <br /> arXiv 2017 &nbsp; <a href="https://arxiv.org/pdf/1707.01521.pdf">Paper</a></div></div><div class="wj-pagination"> <span>&laquo; Prev</span> <span class="active">1</span> <a href="/publications/2/index.html" title="Publications - page 2">2</a> <a href="/publications/2/">Next &raquo;</a></div></article> </main> </main><div id="search-container"></div><hr class="dashed"><footer><div class="text-right"> <p class="copy">Avatar photo credit to <a href="https://cseweb.ucsd.edu/~hhuang/">Haochen Huang</a></p></div></footer></div></div></div></div><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script> $(document).ready(function() { $(".loader").hide(); });</script><script> $("#search-input").keyup(function() { $("main").hide(); $("search-container").show(); if (!$('#search-input').val()) { $("main").show(); $("search-container").hide(); } });</script><script src="/assets/js/jekyll-search.min.js" type="text/javascript"></script><script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-container'), searchResultTemplate: '<a class="nostyle" href="{url}"><div class="blog borders cards"><div class="image" style="background-image: url({image});"></div><div class="content"><h3 class="title">{title}</h3><p class="description">{description}</p></div></div></a>', noResultsText: 'No results found', json: '/search.json' })</script><script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script><script> AOS.init({ duration: 600, once: true, disable: 'mobile' });</script></body></html>